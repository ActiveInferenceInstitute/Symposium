{
  "timestamp": "2025-10-31T15:10:37.483621",
  "content": "Below is a deep, comprehensive research profile on **Alisa Sheinkman**, an Active Inference Symposium participant affiliated with the University of Edinburgh, based on exhaustive multi-source web research.\n\n---\n\n## 1. Academic Background\n\n- **Educational History:**\n  - PhD in Bayesian Deep Learning / Probabilistic Machine Learning, University of Edinburgh, expected 2025.  \n    - PhD thesis: *Probabilistic inference in Bayesian neural networks* supervised by Sara Wade, focusing on scalable variational inference and Bayesian model choice in overparametrized deep models [1](https://sheinkmana.github.io), [7](https://scholar.google.com/citations?user=C-jUAAcAAAAJ&hl=ru).\n  - No explicit prior degrees publicly listed; inferred strong quantitative and statistical background consistent with advanced machine learning research.\n\n- **Research Areas & Expertise:**\n  - Bayesian deep learning and probabilistic machine learning, particularly:\n    - Scalable variational inference algorithms (stochastic, black box variational inference)\n    - Bayesian neural network architecture specification\n    - Model combination and model choice under big data and overparametrization\n  - Applied AI in noisy data contexts (e.g., noise annoyance detection) [1](https://sheinkmana.github.io).\n\n- **Current Academic Position:**\n  - Recent doctoral graduate, University of Edinburgh, associated with Maxwell Institute for Mathematical Sciences and School of Mathematics [3](https://maths.ed.ac.uk/people/a-z), [4](https://www.maxwell.ac.uk/person/alisa-sheinkman/).\n  - Email listed as s2067879@ed.ac.uk confirms active affiliation [3](https://maths.ed.ac.uk/people/a-z).\n\n- **Notable Achievements & Grants:**\n  - Accepted paper at NeurIPS 2025 on surrogate models standards in AI [1](https://sheinkmana.github.io).\n  - ECML PKDD 2025 conference publication on Bayesian neural networks [5](https://ecmlpkdd.org/2025/accepted-papers-rt/).\n  - No public records of formal awards or external grants yet, consistent with being a recent PhD graduate.\n\n- **Academic Profiles:**\n  - Personal research page: https://sheinkmana.github.io [1]\n  - Google Scholar: https://scholar.google.com/citations?user=C-jUAAcAAAAJ&hl=ru [7]\n  - ORCID: https://orcid.org/0009-0002-5926-1929 (verified via query)\n  - Institutional profile: https://www.maxwell.ac.uk/person/alisa-sheinkman/ [4]\n\n---\n\n## 2. Research Contributions\n\n- **Key Publications:**\n\n| Title                                                                                         | Venue/Journal                          | Year | DOI / Link                                                      |\n|-----------------------------------------------------------------------------------------------|-------------------------------------|------|----------------------------------------------------------------|\n| *Probabilistic inference in Bayesian neural networks*                                        | PhD Dissertation, Univ. Edinburgh   | 2025 | https://sheinkmana.github.io (Thesis abstract) [1]             |\n| *SMRS: advocating a unified reporting standard for surrogate models in the artificial intelligence era* | NeurIPS (accepted)                   | 2025 | https://sheinkmana.github.io (NeurIPS accepted paper) [1]       |\n| *Understanding the Trade-offs in Accuracy and Uncertainty Quantification: Architecture and Inference Choices in Bayesian Neural Networks* | ECML PKDD Proceedings                | 2025 | https://ecmlpkdd.org/2025/accepted-papers-rt/ [5]              |\n| *Variational Bayesian Bow tie Neural Networks with Shrinkage*                                | arXiv preprint arXiv:2411.11132     | 2024 | https://arxiv.org/abs/2411.11132 [1]                            |\n| *Deep learning techniques for noise annoyance detection*                                    | Journal of the Acoustical Society of America | 2023 | https://asa.scitation.org/doi/10.1121/10.0019849 (abstract) [1] |\n\n- **Research Focus & Methodologies:**\n  - Bayesian deep learning with focus on scalable inference methods suitable for large-scale neural networks.\n  - Variational inference techniques including stochastic and black box variants.\n  - Emphasis on uncertainty quantification and architecture design in Bayesian neural networks.\n  - Application of deep learning to noise annoyance detection and surrogate modeling standards in AI.\n  - Use of probabilistic modeling and variational Bayesian approaches [1][5].\n\n- **Citation Metrics:**\n  - Google Scholar shows limited citations due to recent publications and dissertation status, with h-index currently low (typical for early-career researchers) [7].\n\n- **Collaborative Networks:**\n  - Frequent co-author: Sara Wade (supervisor and collaborator) [1][5].\n  - Collaborations with researchers involved in surrogate modeling and AI standards (e.g., E. Semenova, T. J. Hitge) [1].\n\n- **Recent Preprints:**\n  - \"Variational Bayesian Bow tie Neural Networks with Shrinkage\" (2024) on arXiv [1].\n\n---\n\n## 3. Professional Experience\n\n- **Employment History:**\n  - Primarily academic PhD researcher at University of Edinburgh until 2025 [1][3][4].\n  - No publicly listed industry experience or consulting roles found.\n\n- **Professional Affiliations:**\n  - Member of Maxwell Institute for Mathematical Sciences, University of Edinburgh [4].\n  - Active in AI and machine learning research groups at Edinburgh.\n\n- **Leadership Roles:**\n  - No public records of formal leadership roles or society memberships beyond research groups.\n\n- **Patents / Technical Reports:**\n  - No patents or technical reports publicly available.\n\n---\n\n## 4. Active Inference & Related Research\n\n- **Direct Connections to Active Inference:**\n  - No explicit publications or projects directly labeled as \"Active Inference.\"\n  - Research on Bayesian neural networks and probabilistic inference is conceptually adjacent and methodologically relevant to Active Inference frameworks [1].\n\n- **Adjacent Fields:**\n  - Expertise in Bayesian inference, variational inference, probabilistic modeling, and uncertainty quantification aligns with core methodologies in Active Inference and free energy principle research [1][5].\n\n- **Methodological Overlap:**\n  - Use of variational Bayesian methods and scalable inference algorithms is compatible with computational neuroscience and Active Inference modeling approaches [1].\n\n- **Potential Applications:**\n  - Her work on Bayesian neural network compression and uncertainty quantification could enhance computational models in Active Inference.\n  - Surrogate modeling standards advocated in her NeurIPS paper may improve reproducibility in Active Inference simulations [1].\n\n- **Research Gaps Addressed:**\n  - Efficient scalable inference in complex Bayesian models, which is a key challenge in computational neuroscience and Active Inference modeling [1].\n\n---\n\n## 5. Academic & Professional Network\n\n- **Key Collaborators:**\n  - Sara Wade (PhD supervisor), University of Edinburgh [1][5].\n  - Collaborators include E. Semenova, T. J. Hitge, S.M. Hall, and others in AI and machine learning communities [1].\n\n- **Conference Presentations:**\n  - ECML PKDD 2025 (Bayesian neural networks paper) [5].\n  - NeurIPS 2025 accepted paper on surrogate modeling standards [1].\n\n- **Workshop Participation:**\n  - Co-author in workshop on deep learning for noise annoyance detection at Alan Turing Institute, 2023 [1].\n\n- **Community Engagement:**\n  - Code repositories linked to publications (e.g., Bayesian neural networks) available on personal website GitHub links [1].\n\n- **Social Media:**\n  - No publicly found Twitter/X or other social media accounts tied to research.\n\n---\n\n## 6. Online Presence & Resources\n\n| Resource                  | Link                                                                                   |\n|---------------------------|----------------------------------------------------------------------------------------|\n| Personal Website          | [https://sheinkmana.github.io](https://sheinkmana.github.io)                           |\n| Google Scholar Profile    | [https://scholar.google.com/citations?user=C-jUAAcAAAAJ&hl=ru](https://scholar.google.com/citations?user=C-jUAAcAAAAJ&hl=ru) |\n| ResearchGate Profile      | Not found publicly                                                                       |\n| LinkedIn Profile          | Not publicly available or not found                                                   |\n| GitHub / Code Repos      | Linked from personal website for publications (e.g., Bayesian NN code) [1]             |\n| Twitter/X Profile         | Not found                                                                              |\n| ORCID Profile            | [https://orcid.org/0009-0002-5926-1929](https://orcid.org/0009-0002-5926-1929)         |\n| Institutional Profile    | [https://www.maxwell.ac.uk/person/alisa-sheinkman/](https://www.maxwell.ac.uk/person/alisa-sheinkman/) |\n\n---\n\n## 7. Future Potential & Opportunities\n\n- **Emerging Research Directions:**\n  - Continued development in scalable Bayesian neural networks and uncertainty quantification.\n  - Potential expansion into surrogate modeling standards, improving AI reproducibility [1].\n  - Possible convergence with Active Inference research due to shared probabilistic frameworks.\n\n- **Opportunities for Growth:**\n  - Bridging scalable Bayesian deep learning with computational neuroscience and Active Inference models.\n  - Collaboration opportunities with leaders in Bayesian AI and theoretical neuroscience (e.g., Sara Wadeâ€™s group).\n\n- **Potential Impact:**\n  - Advancing efficient inference in Bayesian models can accelerate AI models underpinning Active Inference frameworks.\n  - Contribution to AI reproducibility standards aligns with growing community needs in neuroscience and AI research.\n\n- **Strategic Collaboration:**\n  - Potential collaborators include Sara Wade (supervisor), researchers at the Maxwell Institute, and Active Inference symposium participants with Bayesian modeling expertise.\n\n---\n\n# References\n\n1. Alisa Sheinkman personal website and publications: https://sheinkmana.github.io  \n2. Active Inference Symposium participants list (limited info on Sheinkman): https://static1.squarespace.com/static/674f3d64ac0f39221c7d3253/t/67bde78e9534ca167bad9331/1740498831484/Delegates+Pack+final+(1)-compressed.pdf  \n3. University of Edinburgh School of Mathematics staff directory: https://maths.ed.ac.uk/people/a-z  \n4. Maxwell Institute profile for Alisa Sheinkman: https://www.maxwell.ac.uk/person/alisa-sheinkman/  \n5. ECML PKDD 2025 accepted papers including Sheinkmanâ€™s: https://ecmlpkdd.org/2025/accepted-papers-rt/  \n6. Maxwell Institute research themes: https://www.maxwell.ac.uk/research/structure-and-symmetry/  \n7. Google Scholar profile: https://scholar.google.com/citations?user=C-jUAAcAAAAJ&hl=ru  \n\n---\n\nThis profile consolidates all verifiable data up to October 2025, highlighting Alisa Sheinkmanâ€™s emerging prominence in Bayesian deep learning with relevant intersections to Active Inference research.",
  "metadata": {
    "participant": "Alisa Sheinkman",
    "report_type": "background_research"
  }
}
# Background Research: Alisa Sheinkman

Generated on: 2025-10-24 14:49:42

## Metadata

- **participant**: Alisa Sheinkman
- **report_type**: background_research

---

## Academic Background

**Educational History**  
Alisa Sheinkman completed her Doctor of Philosophy (PhD) at the University of Edinburgh, with the degree conferred on July 21, 2025[5]. The title of her thesis is "Probabilistic Inference in..." (full title not provided in the snippet, but the abstract indicates a focus on neural network interpretability)[5]. She began her PhD in algebraic geometry and non-commutative geometry but later switched topics after approximately 1.5 years[3]. No information is available about her undergraduate or master’s degrees, institutions, or graduation years from the provided sources.  
**Institutional Profile:** University of Edinburgh School of Mathematics PhD student page[2].

**Research Areas and Expertise**  
Sheinkman’s research expertise spans Bayesian deep learning, scalable inference algorithms, and building machine learning models with a focus on interpretability, reliability, and uncertainty quantification[4]. Her doctoral work addresses the lack of transparency in neural networks, aiming to develop methods for human-understandable interpretations[5]. Earlier in her PhD, she explored algebraic geometry and non-commutative geometry before shifting to machine learning and probabilistic inference[3].

**Current and Past Academic Positions**  
Sheinkman is listed as a postgraduate student (PhD) at the University of Edinburgh’s School of Mathematics[2]. There is no evidence of previous academic positions, industry roles, or postdoctoral appointments in the available sources.

**Notable Achievements, Awards, Grants, Honors**  
No awards, grants, or honors are listed in the available sources. Sheinkman participated as an organizer for a satellite event at the UoE Centre for Statistics annual conference in June 2022[3].

**Academic Profile Pages**  
- **Institutional Profile:** University of Edinburgh School of Mathematics[2]  
- **Google Scholar:** [Alisa Sheinkman - Google Scholar][6] (4 citations, focus on Bayesian statistics and machine learning)  
- **ORCID:** [0009-0002-5926-1929](https://orcid.org/0009-0002-5926-1929) (no detailed profile found in search results)  
- **Personal Website:** [Alisa Sheinkman’s GitHub Page][3]  
- **CV:** [Alisa Sheinkman CV][4] (hosted on personal GitHub)

## Research Contributions

**Key Publications**  
Only one academic document is directly accessible: her PhD thesis, "Probabilistic Inference in..." (University of Edinburgh, 2025)[5]. No peer-reviewed journal articles, conference papers, or preprints are listed in the search results. Her Google Scholar profile shows 4 citations but does not list specific publications[6].

**Research Focus Areas and Methodologies**  
Sheinkman’s research focuses on probabilistic inference, Bayesian deep learning, and scalable algorithms for machine learning, with an emphasis on model interpretability and uncertainty quantification[4][5]. Her work seeks to address the "black box" nature of neural networks by developing methods for human-understandable interpretations[5].

**Citation Metrics**  
Her Google Scholar profile indicates 4 citations as of the latest available data[6]. No h-index or detailed citation analysis is available.

**Collaborative Networks**  
No information is available on frequent co-authors, research groups, or collaborative networks.

**Recent Preprints and Working Papers**  
No preprints on arXiv, bioRxiv, or similar platforms are found in the search results.

## Professional Experience

**Employment History**  
No evidence of industry experience, consulting work, or previous academic employment is available in the provided sources. Sheinkman is currently a PhD student at the University of Edinburgh[2].

**Professional Affiliations and Society Memberships**  
No information is available regarding professional society memberships or affiliations.

**Leadership Roles**  
Sheinkman co-organized a satellite event for PhD students at the UoE Centre for Statistics annual conference in June 2022[3].

**Patents, Technical Reports, or Applied Work**  
No patents, technical reports, or applied projects are listed.

## Active Inference & Related Research

**Direct Connections to Active Inference**  
There is no direct evidence in the available sources that Sheinkman has published or presented on Active Inference specifically. Her research intersects with Bayesian inference, probabilistic modeling, and interpretable machine learning—fields closely related to Active Inference and the free energy principle[4][5]. However, no explicit mention of Active Inference, the free energy principle, or computational neuroscience is found in her thesis abstract or CV[4][5].

**Adjacent Fields**  
Her expertise in Bayesian statistics, scalable inference, and model interpretability positions her work adjacent to Active Inference, which also relies heavily on Bayesian methods and probabilistic models[4][5]. The lack of explicit engagement with computational neuroscience or the free energy principle suggests her work is more aligned with general machine learning interpretability than with Active Inference per se.

**Methodological Overlap**  
Sheinkman’s methodological toolbox includes Bayesian deep learning and scalable inference algorithms, which are relevant to the mathematical frameworks used in Active Inference[4][5]. Her focus on uncertainty quantification and interpretability could potentially enrich Active Inference models, though this remains an inference rather than a demonstrated connection.

**Potential Applications and Research Gaps**  
Her work on making neural networks more interpretable could address a key gap in Active Inference research: the development of more transparent and explainable generative models[5]. However, this potential is not explicitly realized in her published work to date.

## Academic & Professional Network

**Key Collaborators**  
No information on collaborators, joint publications, or research groups is available.

**Conference Presentations**  
Sheinkman attended and helped organize a satellite event at the UoE Centre for Statistics annual conference in June 2022[3]. No other conference presentations or talks are documented.

**Workshop Organization or Participation**  
No additional workshops or seminar participations are listed.

**Community Engagement**  
No blog posts, tutorials, or code repositories beyond her personal GitHub page are found. Her GitHub does not appear to host significant open-source projects or educational materials[3].

**Social Media Presence**  
No LinkedIn, Twitter/X, ResearchGate, or other professional social media profiles are found in the search results.

## Online Presence & Resources

- **Personal Website/Research Page:** [Alisa Sheinkman GitHub][3]  
- **Google Scholar:** [Alisa Sheinkman - Google Scholar][6]  
- **ResearchGate:** Not found  
- **LinkedIn:** Not found  
- **GitHub:** [sheinkmana][3]  
- **Twitter/X:** Not found  
- **ORCID:** [0009-0002-5926-1929](https://orcid.org/0009-0002-5926-1929)  
- **Institutional Profile:** [University of Edinburgh School of Mathematics][2]  
- **Videos, Podcasts, Interviews:** None found

## Future Potential & Opportunities

**Emerging Research Directions**  
Based on her thesis, Sheinkman is positioned to contribute to the growing field of interpretable and reliable machine learning, with potential applications in Active Inference for developing more transparent generative models[5]. Her expertise in Bayesian methods and uncertainty quantification could fill gaps in current Active Inference research, particularly around model explainability.

**Opportunities for Growth in Active Inference**  
Sheinkman’s skill set aligns well with the methodological needs of the Active Inference community, especially in making complex models more accessible and interpretable[4][5]. Engaging directly with Active Inference literature and collaborating with researchers in computational neuroscience could amplify her impact.

**Potential Impact on the Field**  
If Sheinkman applies her interpretability-focused Bayesian approaches to Active Inference, she could help bridge the gap between theoretical generative models and practical, explainable AI systems[5]. However, this remains speculative without evidence of direct engagement with the field.

**Strategic Collaboration Opportunities**  
Collaboration with Active Inference groups—particularly those focused on Bayesian methods, model transparency, and uncertainty quantification—would be mutually beneficial. No specific potential collaborators are identified in the available sources.

## References

[1] [https://www.maxwell.ac.uk/person/alisa-sheinkman/](https://www.maxwell.ac.uk/person/alisa-sheinkman/)  
[2] [https://maths.ed.ac.uk/people/phd?person=899](https://maths.ed.ac.uk/people/phd?person=899)  
[3] [https://sheinkmana.github.io/moreinfo/](https://sheinkmana.github.io/moreinfo/)  
[4] [https://sheinkmana.github.io/assets/pdf/ASheinkman_CV.pdf](https://sheinkmana.github.io/assets/pdf/ASheinkman_CV.pdf)  
[5] [https://era.ed.ac.uk/bitstream/handle/1842/43738/Sheinkman2025.pdf?sequence=1](https://era.ed.ac.uk/bitstream/handle/1842/43738/Sheinkman2025.pdf?sequence=1)  
[6] [https://scholar.google.com/citations?user=C-jUAAcAAAAJ](https://scholar.google.com/citations?user=C-jUAAcAAAAJ)  

**Note:** Several key details—such as undergraduate education, full publication record, professional social media presence, and direct engagement with Active Inference—are not available in the current search results. This profile reflects all verifiable information as of October 2025.